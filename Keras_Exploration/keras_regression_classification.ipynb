{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Exploration\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# data management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# model objects\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# metrics & evaluation\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# MISC.\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Implement a Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>disease_progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  disease_progression  \n",
       "0 -0.002592  0.019908 -0.017646                151.0  \n",
       "1 -0.039493 -0.068330 -0.092204                 75.0  \n",
       "2 -0.002592  0.002864 -0.025930                141.0  \n",
       "3  0.034309  0.022692 -0.009362                206.0  \n",
       "4 -0.002592 -0.031991 -0.046641                135.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing diabetes dataset\n",
    "diabetes_ds = load_diabetes()\n",
    "diabetes_df = pd.DataFrame(diabetes_ds.data, columns=diabetes_ds.feature_names)\n",
    "diabetes_df['disease_progression'] = diabetes_ds.target\n",
    "\n",
    "diabetes_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (309, 10)\n",
      "X_test: (133, 10)\n"
     ]
    }
   ],
   "source": [
    "# splitting data\n",
    "X = diabetes_df.iloc[:, :-1]\n",
    "y = diabetes_df['disease_progression']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Training Data): 53.198991057883404\n",
      "RMSE (Testing Data): 55.251977123821\n"
     ]
    }
   ],
   "source": [
    "# MLP regressor\n",
    "mlpReg = MLPRegressor(random_state=1, max_iter=3500).fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = mlpReg.predict(X_train)\n",
    "y_test_pred = mlpReg.predict(X_test)\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print('RMSE (Training Data):', rmse_train)\n",
    "print('RMSE (Testing Data):', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Keras Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (622, 14)\n",
      "X_test: (267, 14)\n"
     ]
    }
   ],
   "source": [
    "# importing and cleaning the titanic dataset (same cleaning from assignment 3)\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "titanic_df.drop(columns=['deck', 'alive', 'class'], inplace=True)  # deck (too many nulls) & alive/class (redundant columns)\n",
    "\n",
    "# median age per class for imputations\n",
    "medians = list(titanic_df.groupby(['pclass'])['age'].median())\n",
    "\n",
    "# function for age imputations\n",
    "def impute_age(row):\n",
    "    if pd.isna(row[0]):\n",
    "        if row[1] == 1:\n",
    "            return medians[0]\n",
    "        elif row[1] == 2:\n",
    "            return medians[1]\n",
    "        elif row[1] == 3:\n",
    "            return medians[2]\n",
    "    else:\n",
    "        return row[0]\n",
    "\n",
    "titanic_df['age'] = titanic_df[['age', 'pclass']].apply(impute_age, axis=1)\n",
    "\n",
    "titanic_df.dropna(inplace=True)  # dropping any remaing records with nulls\n",
    "\n",
    "# create dummy variables for sex, embarked, who, adult_male, embark_town, alone\n",
    "titanic_df = pd.get_dummies(titanic_df, columns=['sex', 'embarked', 'who', 'adult_male', \n",
    "                                                 'embark_town', 'alone'], drop_first=True)\n",
    "\n",
    "# create 'label' from survived column\n",
    "labels = titanic_df['survived']\n",
    "\n",
    "# create 'features' from dropping survived\n",
    "features = titanic_df.drop(columns=['survived'])\n",
    "\n",
    "\n",
    "# 70/30 split for data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=17)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                450       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                620       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 105       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,181\n",
      "Trainable params: 1,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=len(X_train.columns)))  # input layer\n",
    "model.add(Dense(20, activation=\"relu\"))  # hidden layer 1\n",
    "model.add(Dense(5, activation=\"relu\"))  # hidden layer 2\n",
    "model.add(Dense(1, activation=\"sigmoid\"))  # output layer\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 871us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Accuracy (Training Data): 0.7942122186495176\n",
      "F1 (Training Data): 0.7077625570776256\n",
      "\n",
      "Accuracy (Testing Data): 0.8277153558052435\n",
      "F1 (Testing Data): 0.787037037037037\n"
     ]
    }
   ],
   "source": [
    "# compiling model\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# fitting model\n",
    "model.fit(X_train, y_train, epochs=40, verbose=0)\n",
    "\n",
    "# predicting on the training data\n",
    "y_train_proba = model.predict(X_train)\n",
    "y_train_pred = np.round(y_train_proba).astype(int)\n",
    "\n",
    "# predicting on the test data\n",
    "y_test_proba = model.predict(X_test)\n",
    "y_test_pred = np.round(y_test_proba).astype(int)\n",
    "\n",
    "print('Accuracy (Training Data):', accuracy_score(y_train, y_train_pred))\n",
    "print('F1 (Training Data):', f1_score(y_train, y_train_pred))\n",
    "print('\\nAccuracy (Testing Data):', accuracy_score(y_test, y_test_pred))\n",
    "print('F1 (Testing Data):', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3: Keras Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12165, 53)\n",
      "X_test: (5214, 53)\n"
     ]
    }
   ],
   "source": [
    "# loading bike share data\n",
    "bike_df = pd.read_csv('bike_share_hour.csv')  # predicting cnt\n",
    "\n",
    "# convert columns to categorical\n",
    "cat_vars = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "bike_df[cat_vars] = bike_df[cat_vars].astype('category')\n",
    "\n",
    "# scale numerical features with StandardScaler() (temp, atemp, hum, windspeed)\n",
    "numerical_cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "bike_df[numerical_cols] = StandardScaler().fit_transform(bike_df[numerical_cols])\n",
    "\n",
    "# dropping unused columns\n",
    "bike_df = bike_df.drop(columns=['instant', 'dteday', 'casual', 'registered'])\n",
    "\n",
    "# OHE for categorical columns\n",
    "bike_df = pd.get_dummies(bike_df, columns=cat_vars, drop_first=True)\n",
    "\n",
    "# split into training and test data (70/30 split)\n",
    "features = bike_df.drop('cnt', axis=1)\n",
    "labels = bike_df['cnt']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=17)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 30)                1620      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                620       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 105       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,351\n",
      "Trainable params: 2,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=len(X_train.columns), activation=\"relu\"))  # input layer\n",
    "model.add(Dense(20, activation=\"relu\"))  # hidden layer 1\n",
    "model.add(Dense(5, activation=\"relu\"))  # hidden layer 2\n",
    "model.add(Dense(1))  # output layer\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 629us/step\n",
      "163/163 [==============================] - 0s 618us/step\n",
      "RMSE (Training Data): 41.7425021316964\n",
      "RMSE (Testing Data): 45.39439708941542\n"
     ]
    }
   ],
   "source": [
    "# compiling model\n",
    "model.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['mse'])\n",
    "\n",
    "# fitting model\n",
    "model.fit(X_train, y_train, epochs=40, verbose=0)\n",
    "\n",
    "# predicting on the training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# predicting on the test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print('RMSE (Training Data):', rmse_train)\n",
    "print('RMSE (Testing Data):', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4: Tuning the Keras Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 438, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 438, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [            nan  -2233.06743867  -2276.48087616 -68822.53446571\n",
      " -36723.08290682  -4612.06681342  -2242.83926823 -38575.02806189]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--GridSearch Results--\n",
      "Best RMSE: 47.255342964272145\n",
      "Best Parameters {'optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "# create model function\n",
    "def build_model(optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=len(X_train.columns), activation=\"relu\"))  # input layer\n",
    "    model.add(Dense(20, activation=\"relu\"))  # hidden layer 1\n",
    "    model.add(Dense(5, activation=\"relu\"))  # hidden layer 2\n",
    "    model.add(Dense(1))  # output layer\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=build_model, verbose=0)\n",
    "\n",
    "optimizers = ['SGD', 'RMSprop', 'Adam', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']\n",
    "param_grid = dict(optimizer=optimizers)\n",
    "\n",
    "gs = GridSearchCV(estimator=model,\n",
    "                  param_grid=param_grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  verbose=0)\n",
    "\n",
    "gs_model = gs.fit(X_train, y_train, epochs=40)\n",
    "\n",
    "print(\"--GridSearch Results--\")\n",
    "print(\"Best RMSE:\", np.sqrt(-gs_model.best_score_))\n",
    "print(\"Best Parameters\", gs_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n",
      "RMSE: 44.95981888524411\n"
     ]
    }
   ],
   "source": [
    "# Test Data\n",
    "y_test_pred = gs_model.predict(X_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Test Data\")\n",
    "print(\"RMSE:\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
